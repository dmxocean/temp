{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Captioning: Exploratory Data Analysis\n",
    "\n",
    "This notebook performs exploratory data analysis on the Flickr8k dataset:\n",
    "- Dataset statistics\n",
    "- Caption analysis\n",
    "- Image properties\n",
    "- Vocabulary analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Add project root to path\n",
    "project_root = os.path.dirname(os.getcwd())\n",
    "sys.path.append(project_root)\n",
    "\n",
    "# Import project modules\n",
    "from src.utils.config import load_config\n",
    "from src.utils.constants import SEED\n",
    "from src.preprocessing.vocabulary import preprocess_caption\n",
    "\n",
    "# Set style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'captions_file'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m data_config \u001b[38;5;241m=\u001b[39m load_config(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Get paths\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m captions_file \u001b[38;5;241m=\u001b[39m \u001b[43mdata_config\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdataset\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcaptions_file\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      6\u001b[0m images_dir \u001b[38;5;241m=\u001b[39m data_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages_dir\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCaptions file: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaptions_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'captions_file'"
     ]
    }
   ],
   "source": [
    "# Load configuration\n",
    "data_config = load_config('data')\n",
    "\n",
    "# Get paths\n",
    "captions_file = data_config['dataset']['captions_file']\n",
    "images_dir = data_config['dataset']['images_dir']\n",
    "\n",
    "print(f\"Captions file: {captions_file}\")\n",
    "print(f\"Images directory: {images_dir}\")\n",
    "\n",
    "# Check if files exist\n",
    "print(f\"\\nCaptions file exists: {os.path.exists(captions_file)}\")\n",
    "print(f\"Images directory exists: {os.path.exists(images_dir)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/raw/flickr8k/captions.txt\n"
     ]
    }
   ],
   "source": [
    "print(captions_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/raw/flickr8k/captions.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load captions\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m captions_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcaptions_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaptions_df\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mColumns: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaptions_df\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\dmxocean\\miniconda3\\envs\\DL\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dmxocean\\miniconda3\\envs\\DL\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\dmxocean\\miniconda3\\envs\\DL\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dmxocean\\miniconda3\\envs\\DL\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\dmxocean\\miniconda3\\envs\\DL\\lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/raw/flickr8k/captions.txt'"
     ]
    }
   ],
   "source": [
    "# Load captions\n",
    "captions_df = pd.read_csv(captions_file)\n",
    "print(f\"Dataset shape: {captions_df.shape}\")\n",
    "print(f\"\\nColumns: {captions_df.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "captions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "num_images = len(captions_df['image'].unique())\n",
    "num_captions = len(captions_df)\n",
    "avg_captions_per_image = num_captions / num_images\n",
    "\n",
    "print(\"Dataset Statistics:\")\n",
    "print(f\"Total unique images: {num_images}\")\n",
    "print(f\"Total captions: {num_captions}\")\n",
    "print(f\"Average captions per image: {avg_captions_per_image:.2f}\")\n",
    "\n",
    "# Check caption distribution per image\n",
    "caption_counts = captions_df['image'].value_counts()\n",
    "print(f\"\\nCaptions per image distribution:\")\n",
    "print(caption_counts.value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caption Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process captions\n",
    "print(\"Processing captions...\")\n",
    "captions_df['processed_caption'] = captions_df['caption'].apply(preprocess_caption)\n",
    "captions_df['caption_length'] = captions_df['processed_caption'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# Caption length statistics\n",
    "print(\"\\nCaption Length Statistics:\")\n",
    "print(captions_df['caption_length'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caption length distribution\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(captions_df['caption_length'], bins=30, edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Caption Length (words)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Caption Lengths')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "captions_df['caption_length'].plot(kind='box')\n",
    "plt.ylabel('Caption Length (words)')\n",
    "plt.title('Caption Length Box Plot')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word frequency analysis\n",
    "all_words = []\n",
    "for caption in captions_df['processed_caption']:\n",
    "    all_words.extend(caption.split())\n",
    "\n",
    "word_freq = Counter(all_words)\n",
    "print(f\"Total unique words: {len(word_freq)}\")\n",
    "print(f\"Total words: {len(all_words)}\")\n",
    "\n",
    "# Most common words\n",
    "print(\"\\nTop 20 most common words:\")\n",
    "for word, count in word_freq.most_common(20):\n",
    "    print(f\"{word}: {count} ({count/len(all_words)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word cloud visualization\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# All words\n",
    "plt.subplot(1, 2, 1)\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(' '.join(all_words))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.title('Word Cloud - All Words')\n",
    "plt.axis('off')\n",
    "\n",
    "# Without stopwords\n",
    "plt.subplot(1, 2, 2)\n",
    "# Filter out common words\n",
    "stopwords = {'a', 'an', 'the', 'is', 'in', 'on', 'and', 'of', 'with', 'at', 'to', 'are'}\n",
    "filtered_words = [w for w in all_words if w not in stopwords]\n",
    "wordcloud_filtered = WordCloud(width=800, height=400, background_color='white').generate(' '.join(filtered_words))\n",
    "plt.imshow(wordcloud_filtered, interpolation='bilinear')\n",
    "plt.title('Word Cloud - Content Words')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample images for analysis\n",
    "sample_images = captions_df['image'].unique()[:100]  # Analyze first 100 images\n",
    "\n",
    "# Collect image properties\n",
    "image_properties = []\n",
    "\n",
    "for img_name in tqdm(sample_images, desc=\"Analyzing images\"):\n",
    "    img_path = os.path.join(images_dir, img_name)\n",
    "    if os.path.exists(img_path):\n",
    "        img = Image.open(img_path)\n",
    "        image_properties.append({\n",
    "            'filename': img_name,\n",
    "            'width': img.width,\n",
    "            'height': img.height,\n",
    "            'aspect_ratio': img.width / img.height,\n",
    "            'mode': img.mode,\n",
    "            'format': img.format\n",
    "        })\n",
    "\n",
    "image_df = pd.DataFrame(image_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image size distribution\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(image_df['width'], image_df['height'], alpha=0.5)\n",
    "plt.xlabel('Width (pixels)')\n",
    "plt.ylabel('Height (pixels)')\n",
    "plt.title('Image Dimensions')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.hist(image_df['aspect_ratio'], bins=20, edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Aspect Ratio (width/height)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Aspect Ratio Distribution')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "image_df['resolution'] = image_df['width'] * image_df['height']\n",
    "plt.hist(image_df['resolution'] / 1e6, bins=20, edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Resolution (megapixels)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Resolution Distribution')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Image Statistics:\")\n",
    "print(f\"Average width: {image_df['width'].mean():.1f} pixels\")\n",
    "print(f\"Average height: {image_df['height'].mean():.1f} pixels\")\n",
    "print(f\"Average aspect ratio: {image_df['aspect_ratio'].mean():.2f}\")\n",
    "print(f\"Image formats: {image_df['format'].value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caption-Image Relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze caption variation for same image\n",
    "sample_image = captions_df['image'].unique()[0]\n",
    "sample_captions = captions_df[captions_df['image'] == sample_image]\n",
    "\n",
    "print(f\"Sample image: {sample_image}\")\n",
    "print(f\"\\nCaptions for this image:\")\n",
    "for i, (_, row) in enumerate(sample_captions.iterrows(), 1):\n",
    "    print(f\"{i}. {row['caption']}\")\n",
    "    \n",
    "# Display the image\n",
    "img_path = os.path.join(images_dir, sample_image)\n",
    "img = Image.open(img_path)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(img)\n",
    "plt.title(f\"Image: {sample_image}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caption diversity analysis\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Calculate caption similarity for images with multiple captions\n",
    "similarity_scores = []\n",
    "\n",
    "for img in tqdm(captions_df['image'].unique()[:100], desc=\"Calculating similarities\"):\n",
    "    img_captions = captions_df[captions_df['image'] == img]['processed_caption'].tolist()\n",
    "    if len(img_captions) > 1:\n",
    "        # Calculate TF-IDF vectors\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        tfidf_matrix = vectorizer.fit_transform(img_captions)\n",
    "        \n",
    "        # Calculate pairwise similarities\n",
    "        similarities = cosine_similarity(tfidf_matrix)\n",
    "        \n",
    "        # Get upper triangle (excluding diagonal)\n",
    "        for i in range(len(img_captions)):\n",
    "            for j in range(i + 1, len(img_captions)):\n",
    "                similarity_scores.append(similarities[i, j])\n",
    "\n",
    "# Plot similarity distribution\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(similarity_scores, bins=30, edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Cosine Similarity')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Caption Similarities for Same Image')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Average caption similarity: {np.mean(similarity_scores):.3f}\")\n",
    "print(f\"Std caption similarity: {np.std(similarity_scores):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary Analysis with Different Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze vocabulary size with different frequency thresholds\n",
    "thresholds = [1, 2, 3, 4, 5, 10, 20]\n",
    "vocab_sizes = []\n",
    "coverage_rates = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    # Count words above threshold\n",
    "    vocab_size = sum(1 for count in word_freq.values() if count >= threshold) + 4  # +4 for special tokens\n",
    "    vocab_sizes.append(vocab_size)\n",
    "    \n",
    "    # Calculate coverage\n",
    "    covered_words = sum(count for word, count in word_freq.items() if count >= threshold)\n",
    "    coverage = covered_words / len(all_words) * 100\n",
    "    coverage_rates.append(coverage)\n",
    "\n",
    "# Plot results\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('Frequency Threshold')\n",
    "ax1.set_ylabel('Vocabulary Size', color=color)\n",
    "ax1.plot(thresholds, vocab_sizes, 'o-', color=color, linewidth=2, markersize=8)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "color = 'tab:red'\n",
    "ax2.set_ylabel('Word Coverage (%)', color=color)\n",
    "ax2.plot(thresholds, coverage_rates, 's-', color=color, linewidth=2, markersize=8)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "plt.title('Vocabulary Size and Coverage vs Frequency Threshold')\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print table\n",
    "print(\"Threshold | Vocab Size | Coverage\")\n",
    "print(\"-\" * 35)\n",
    "for t, v, c in zip(thresholds, vocab_sizes, coverage_rates):\n",
    "    print(f\"{t:9d} | {v:10d} | {c:7.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary report\n",
    "print(\"DATASET SUMMARY\")\n",
    "print()\n",
    "print(f\"\\nImages:\")\n",
    "print(f\"  Total images: {num_images}\")\n",
    "print(f\"  Average resolution: {image_df['resolution'].mean() / 1e6:.1f} MP\")\n",
    "print(f\"  Most common aspect ratio: {image_df['aspect_ratio'].mode()[0]:.2f}\")\n",
    "\n",
    "print(f\"\\nCaptions:\")\n",
    "print(f\"  Total captions: {num_captions}\")\n",
    "print(f\"  Captions per image: {avg_captions_per_image:.1f}\")\n",
    "print(f\"  Average caption length: {captions_df['caption_length'].mean():.1f} words\")\n",
    "print(f\"  Caption length range: {captions_df['caption_length'].min()}-{captions_df['caption_length'].max()} words\")\n",
    "\n",
    "print(f\"\\nVocabulary:\")\n",
    "print(f\"  Total unique words: {len(word_freq)}\")\n",
    "print(f\"  Words with freq >= 5: {sum(1 for c in word_freq.values() if c >= 5)}\")\n",
    "print(f\"  Most common word: '{word_freq.most_common(1)[0][0]}' ({word_freq.most_common(1)[0][1]} times)\")\n",
    "\n",
    "print(f\"\\nCaption Diversity:\")\n",
    "print(f\"  Average similarity between captions: {np.mean(similarity_scores):.3f}\")\n",
    "print(f\"  This indicates {'high' if np.mean(similarity_scores) > 0.7 else 'moderate' if np.mean(similarity_scores) > 0.4 else 'low'} similarity\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
